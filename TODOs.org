* Training Scripts
** DONE add scripts that build and save CNN models s.t. they can be used as input for train sequence
   CLOSED: [2019-10-16 Wed 12:53]
** DONE train from serialized model instead defining model locally
   CLOSED: [2019-10-16 Wed 12:53]
*** use 'tf.keras.callbacks.ModelCheckpoint' callback to save model during training and at the end
** DONE save trained model before ending training script
   CLOSED: [2019-10-16 Wed 12:53]
** DONE add flag that needs to be activated to allow script running on cluster
   CLOSED: [2019-10-16 Wed 12:54]
** DONE add argparser to 'sequence_to_tfrec.py'
   CLOSED: [2019-10-17 Thu 22:30]
** DONE add 'carla_to_tfrec.py' script that wraps 'sequence_to_tfrec.py' but converts CARLA sequences simpler and safer
   CLOSED: [2019-10-17 Thu 22:32]
** DONE get rid of TFREC_COMPRESSION_TYPE argument
   CLOSED: [2019-10-18 Fri 16:52]
** TODO at model__*.py scripts should no longer use config file as input
*** use list of names as argument as well as full output model name
*** also use list of names as argument at 'train_sequence.py'
** TODO at 'train_sequence.py' add option 'read_from_archive' so that it can be chosen to read the data from zip or directly from disk
*** when reading from archive all files will be unpacked during training besides the archive -> redundant use of memory
*** at 'train_sequence.py': when 'read_from_arch == False' then request a list of filepaths as argument 
** DONE add support for global config file that can be set up once and is passed as single argument to 'train_sequence.py' and 'model__*.py' scripts
   CLOSED: [2019-10-21 Mon 13:29]
*** use pythons builtin configparser combined with the JSON parser as in: https://stackoverflow.com/questions/335695/lists-in-configparser
** TODO modularize code
*** check which functions are used at multiple scripts and put them into util module
*** put code from main script into functions
*** maybe make class for dataset pipeline generation
**** would make it easier to handle global variables like 'image_files' or 'label_files'
** TODO support for training on KITTI sequences which can and will be used as Reference
** TODO support training of unsupervised models. Since current state-of-the-art research is going in that direction it could be used for comparisons.

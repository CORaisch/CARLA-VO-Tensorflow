{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Dummy Data for Demonstration\n",
    "## 1.1 create data in numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_0 = np.array(['rgb_0', 'rgb_1', 'rgb_2', 'rgb_3', 'rgb_4', 'rgb_5'])\n",
    "inputs_1 = np.array(['rgb_1', 'rgb_2', 'rgb_3', 'rgb_4', 'rgb_5', 'rgb_6'])\n",
    "labels   = np.array([['tx01','ty01','tz01','r01','p01','y01'],\n",
    "                     ['tx12','ty12','tz12','r12','p12','y12'],\n",
    "                     ['tx23','ty23','tz23','r23','p23','y23'],\n",
    "                     ['tx34','ty34','tz34','r34','p34','y34'],\n",
    "                     ['tx45','ty45','tz45','r45','p45','y45'],\n",
    "                     ['tx56','ty56','tz56','r56','p56','y56']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 put numpy data into tf.data.Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ZipDataset shapes: (((), ()), (6,)), types: ((tf.string, tf.string), tf.string)>\n"
     ]
    }
   ],
   "source": [
    "## prepare inputs\n",
    "ds_inputs_0 = tf.data.Dataset.from_tensor_slices(inputs_0)\n",
    "ds_inputs_1 = tf.data.Dataset.from_tensor_slices(inputs_1)\n",
    "# create a dataset that returns a tuple (image_0, image_1)\n",
    "ds_inputs   = tf.data.Dataset.zip((ds_inputs_0, ds_inputs_1))\n",
    "\n",
    "## prepare labels\n",
    "ds_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "\n",
    "## zip togeter the input images and the labels s.t. a tuple ((image_0, image_1), labels) is returned\n",
    "ds_zip = tf.data.Dataset.zip((ds_inputs, ds_labels))\n",
    "\n",
    "# print outputshape of ds_zip\n",
    "print(ds_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to train on non-sequence data, ```ds_zip``` could now be batched and shuffled in order to obtain a finalized dataset that can be used for training with the ```tf.keras.model.fit()``` train-loop, i.e. the output shapes of ```ds_zip``` fit the expectations of tf.keras module.\n",
    "But since we want to learn from sequences we first need to do further processing of the dataset pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Slice Dataset into Subsequences\n",
    "what we wish to come up with is a transformation, that takes an array ```[1,2,3,4]``` and outputs for example an array of the form  ```[[1,2], [2,3], [3,4]]```. Such an transformation can be achived with the ```tf.data.Dataset.window()``` function:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<WindowDataset shapes: ((DatasetSpec(TensorSpec(shape=(), dtype=tf.string, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(), dtype=tf.string, name=None), TensorShape([]))), DatasetSpec(TensorSpec(shape=(6,), dtype=tf.string, name=None), TensorShape([]))), types: ((DatasetSpec(TensorSpec(shape=(), dtype=tf.string, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(), dtype=tf.string, name=None), TensorShape([]))), DatasetSpec(TensorSpec(shape=(6,), dtype=tf.string, name=None), TensorShape([])))>\n"
     ]
    }
   ],
   "source": [
    "ds_window_unmapped = ds_zip.window(3,1,1, drop_remainder=True)\n",
    "print(ds_window_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "1. describe need for flat_map --> window() returns dataset of datasets!\n",
    "2. describe mapper function and why to use batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FlatMapDataset shapes: (((None,), (None,)), (None, 6)), types: ((tf.string, tf.string), tf.string)>\n"
     ]
    }
   ],
   "source": [
    "## define class that holds parameterized function to map on dataset\n",
    "class mapper():\n",
    "    def __init__(self, window_size):\n",
    "        self.window_size = window_size\n",
    "        \n",
    "    def map_to_batch(self, *sub):\n",
    "        tmp = tf.data.Dataset.zip(\n",
    "                (tf.data.Dataset.zip((sub[0][0].batch(self.window_size), sub[0][1].batch(self.window_size))),\n",
    "                sub[1].batch(3)))\n",
    "        return tmp\n",
    "    \n",
    "## map entries of windowed dataset into flat arrays of sequences\n",
    "ds_window = ds_window_unmapped.flat_map(mapper(3).map_to_batch)\n",
    "print(ds_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Further process Dataset to get finalized Dataset\n",
    "## 3.1 Map Inputs to Layernames\n",
    "TODO\n",
    "explain why it is better to use inputs that are maped to layernames --> safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ({in_t0: (None,), in_t1: (None,)}, (None, 6)), types: ({in_t0: tf.string, in_t1: tf.string}, tf.string)>\n",
      "iterate dataset:\n",
      "next data:\n",
      "({'in_t0': <tf.Tensor: id=46, shape=(3,), dtype=string, numpy=array([b'rgb_0', b'rgb_1', b'rgb_2'], dtype=object)>, 'in_t1': <tf.Tensor: id=47, shape=(3,), dtype=string, numpy=array([b'rgb_1', b'rgb_2', b'rgb_3'], dtype=object)>}, <tf.Tensor: id=48, shape=(3, 6), dtype=string, numpy=\n",
      "array([[b'tx01', b'ty01', b'tz01', b'r01', b'p01', b'y01'],\n",
      "       [b'tx12', b'ty12', b'tz12', b'r12', b'p12', b'y12'],\n",
      "       [b'tx23', b'ty23', b'tz23', b'r23', b'p23', b'y23']], dtype=object)>)\n",
      "next data:\n",
      "({'in_t0': <tf.Tensor: id=49, shape=(3,), dtype=string, numpy=array([b'rgb_1', b'rgb_2', b'rgb_3'], dtype=object)>, 'in_t1': <tf.Tensor: id=50, shape=(3,), dtype=string, numpy=array([b'rgb_2', b'rgb_3', b'rgb_4'], dtype=object)>}, <tf.Tensor: id=51, shape=(3, 6), dtype=string, numpy=\n",
      "array([[b'tx12', b'ty12', b'tz12', b'r12', b'p12', b'y12'],\n",
      "       [b'tx23', b'ty23', b'tz23', b'r23', b'p23', b'y23'],\n",
      "       [b'tx34', b'ty34', b'tz34', b'r34', b'p34', b'y34']], dtype=object)>)\n",
      "next data:\n",
      "({'in_t0': <tf.Tensor: id=52, shape=(3,), dtype=string, numpy=array([b'rgb_2', b'rgb_3', b'rgb_4'], dtype=object)>, 'in_t1': <tf.Tensor: id=53, shape=(3,), dtype=string, numpy=array([b'rgb_3', b'rgb_4', b'rgb_5'], dtype=object)>}, <tf.Tensor: id=54, shape=(3, 6), dtype=string, numpy=\n",
      "array([[b'tx23', b'ty23', b'tz23', b'r23', b'p23', b'y23'],\n",
      "       [b'tx34', b'ty34', b'tz34', b'r34', b'p34', b'y34'],\n",
      "       [b'tx45', b'ty45', b'tz45', b'r45', b'p45', b'y45']], dtype=object)>)\n",
      "next data:\n",
      "({'in_t0': <tf.Tensor: id=55, shape=(3,), dtype=string, numpy=array([b'rgb_3', b'rgb_4', b'rgb_5'], dtype=object)>, 'in_t1': <tf.Tensor: id=56, shape=(3,), dtype=string, numpy=array([b'rgb_4', b'rgb_5', b'rgb_6'], dtype=object)>}, <tf.Tensor: id=57, shape=(3, 6), dtype=string, numpy=\n",
      "array([[b'tx34', b'ty34', b'tz34', b'r34', b'p34', b'y34'],\n",
      "       [b'tx45', b'ty45', b'tz45', b'r45', b'p45', b'y45'],\n",
      "       [b'tx56', b'ty56', b'tz56', b'r56', b'p56', b'y56']], dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "## define mapping of input images to input layernames s.t. dataset returns dictionaries as inputs\n",
    "def map_to_dict(*sub):\n",
    "    layernames = ['in_t0', 'in_t1'] # dummy layernames\n",
    "    return ({ layernames[i] : sequence for i, sequence in enumerate(sub[0]) }, sub[1])\n",
    "\n",
    "## remap inputs of dataset\n",
    "ds_final = ds_window.map(map_to_dict)\n",
    "print(ds_final)\n",
    "\n",
    "## print entries of dataset\n",
    "print(\"iterate dataset:\")\n",
    "for data in ds_final:\n",
    "    print(\"next data:\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Batch Dataset\n",
    "TODO\n",
    "write text that now we can batch and shuffle the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ({in_t0: (None, None), in_t1: (None, None)}, (None, None, 6)), types: ({in_t0: tf.string, in_t1: tf.string}, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "ds_final_batched = ds_final.batch(batch_size)\n",
    "print(ds_final_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Investigate Elements of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next data:\n",
      "({'in_t0': <tf.Tensor: id=66, shape=(2, 3), dtype=string, numpy=\n",
      "array([[b'rgb_0', b'rgb_1', b'rgb_2'],\n",
      "       [b'rgb_1', b'rgb_2', b'rgb_3']], dtype=object)>, 'in_t1': <tf.Tensor: id=67, shape=(2, 3), dtype=string, numpy=\n",
      "array([[b'rgb_1', b'rgb_2', b'rgb_3'],\n",
      "       [b'rgb_2', b'rgb_3', b'rgb_4']], dtype=object)>}, <tf.Tensor: id=68, shape=(2, 3, 6), dtype=string, numpy=\n",
      "array([[[b'tx01', b'ty01', b'tz01', b'r01', b'p01', b'y01'],\n",
      "        [b'tx12', b'ty12', b'tz12', b'r12', b'p12', b'y12'],\n",
      "        [b'tx23', b'ty23', b'tz23', b'r23', b'p23', b'y23']],\n",
      "\n",
      "       [[b'tx12', b'ty12', b'tz12', b'r12', b'p12', b'y12'],\n",
      "        [b'tx23', b'ty23', b'tz23', b'r23', b'p23', b'y23'],\n",
      "        [b'tx34', b'ty34', b'tz34', b'r34', b'p34', b'y34']]],\n",
      "      dtype=object)>)\n",
      "next data:\n",
      "({'in_t0': <tf.Tensor: id=69, shape=(2, 3), dtype=string, numpy=\n",
      "array([[b'rgb_2', b'rgb_3', b'rgb_4'],\n",
      "       [b'rgb_3', b'rgb_4', b'rgb_5']], dtype=object)>, 'in_t1': <tf.Tensor: id=70, shape=(2, 3), dtype=string, numpy=\n",
      "array([[b'rgb_3', b'rgb_4', b'rgb_5'],\n",
      "       [b'rgb_4', b'rgb_5', b'rgb_6']], dtype=object)>}, <tf.Tensor: id=71, shape=(2, 3, 6), dtype=string, numpy=\n",
      "array([[[b'tx23', b'ty23', b'tz23', b'r23', b'p23', b'y23'],\n",
      "        [b'tx34', b'ty34', b'tz34', b'r34', b'p34', b'y34'],\n",
      "        [b'tx45', b'ty45', b'tz45', b'r45', b'p45', b'y45']],\n",
      "\n",
      "       [[b'tx34', b'ty34', b'tz34', b'r34', b'p34', b'y34'],\n",
      "        [b'tx45', b'ty45', b'tz45', b'r45', b'p45', b'y45'],\n",
      "        [b'tx56', b'ty56', b'tz56', b'r56', b'p56', b'y56']]],\n",
      "      dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "for data in ds_final_batched:\n",
    "    print(\"next data:\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Further Reading\n",
    "If you want to use such a sequenced dataset to train on a model similar to DeepVO (https://www.cs.ox.ac.uk/files/9026/DeepVO.pdf) this Jupyter Notebook will be interesting: http://www.cs.virginia.edu/~vicente/recognition/2016/notebooks/kerasLSTM.html .\n",
    "In that notebook they show how to generally train a LSTM base RNN on sequenced data. They train on sequences of chars in order to generate english sentences. They do not use the ```tf.data.Dataset``` interface and instead they use simple numpy arrays. But this example is shows well how the RNNs need to be trained on sequences and later can be used to infere from single instances (which is principally the way it is done in DeepVO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
